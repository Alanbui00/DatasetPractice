---
title: "Simpsons"
output: html_notebook
---

```{r}
library(httr)
library(tidyverse)
library(jsonlite)
library(withr)
simpsons_characters <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_characters.csv')
simpsons_episodes <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_episodes.csv')
simpsons_locations <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_locations.csv')
simpsons_script_lines <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_script_lines.csv')
```
General Data Exploration
Questions
1. What kind of insights can you extract from this dataset?
2. How would you clean and preprocess this data for analysis?
3. Are there any missing values or anomalies in the dataset? How would you handle them?

Answers
1. how viewership changed, how ratings changed, word cloud, dialogue trends
2. make sure all columns have correct data type, get rid of NA standardize text, merging data
3. Yes, check for errors, fill in missing data if possible or get rid of the row


Data Wrangling & SQL-style Queries

1. How would you join the simpsons_script_lines.csv with simpsons_characters.csv to get the names of the characters speaking each line?
2. How would you find the top 5 locations where the most dialogue happens?
3. Write a query to retrieve all episodes that aired in the year 2010 with an IMDb rating above 7.0.

```{r}
#1. How would you join the simpsons_script_lines.csv with simpsons_characters.csv to get the names of the characters speaking each line?

script_characters <- simpsons_script_lines %>%
  left_join(simpsons_characters, by = c("character_id" = "id")) %>%
  mutate(name = ifelse(is.na(name), "Unknown", name))

head(script_characters, 2)
```

```{r}
#2. How would you find the top 5 locations where the most dialogue happens?
top_loc <- simpsons_script_lines %>%
  count(location_id, sort = TRUE) %>%
  left_join(simpsons_locations, by = c("location_id" = "id")) %>%
  select(n, name) 

head(top_loc)
```
```{r}
#3. Write a query to retrieve all episodes that aired in the year 2010 with an IMDb rating above 7.0.
#head(simpsons_episodes)
#colnames(simpsons_episodes)
year2010rating7 <- simpsons_episodes %>%
  select(id, imdb_rating, original_air_year, title, season) %>%
  filter(original_air_year == 2010 & imdb_rating > 7.0)


head(year2010rating7)
```

```{r}
#which season has the best average rating
head(simpsons_episodes)

bestRating <- simpsons_episodes %>%
  select(imdb_rating, season, title) %>%
  group_by(season) %>%
  summarise(avg_rating = mean(imdb_rating, na.rm = TRUE))

ggplot(bestRating, aes(x = factor(season), y = avg_rating)) +
  geom_col(fill = "steelblue") +
  labs(title = "Average rating per Seasons", 
       x = "Season", 
       y = "Rating") +
  theme_classic()

head(bestRating)
```

Exploratory Data Analysis (EDA)
7 What are some key trends you could explore in Simpsons' episode ratings over the years?
8 How would you visualize the most frequently spoken words in the scripts?
9 How would you determine which character has the most spoken lines in the series?

```{r}
# 7 What are some key trends you could explore in Simpsons' episode ratings over the years?
episodes <- simpsons_episodes
episodes <- na.omit(episodes)
ggplot(episodes, aes(x = original_air_date, y = imdb_rating)) +
  geom_line()

ggplot(episodes, aes(x = as.Date(original_air_date), y = imdb_rating)) +
  geom_point(alpha = .5, color = "yellow") +
  geom_smooth(method = "lm", color = "blue", se = TRUE) +
  labs(title = "Ratings over year linear model", 
       x = "Year", 
       y = "Ratings") +
  theme_minimal()
  
```
```{r}
#8 How would you visualize the most frequently spoken words in the scripts?
#install.packages("tm")
library(tm)
#install.packages("wordcloud")
library(wordcloud)

# preprocess data
script_text <- simpsons_script_lines$normalized_text
script_text <- na.omit(script_text)
preprocess <- function(text){
  text <- tolower(text)
  text <- removePunctuation(text)  
  text <- removeNumbers(text)
  text <- removeWords(text, stopwords(kind = "en"))
  return(text)
}
script_text <- sapply(script_text, preprocess)

words.vec <- VectorSource(script_text)
words.corpus <- Corpus(words.vec)
words.corpus

tdm <- TermDocumentMatrix(words.corpus)
m <- as.matrix(tdm)
wordcount <- rowSums(m)
head(wordcount)
wordcount <- sort(wordcount, decreasing = TRUE)
wordcloud(names(wordcount), wordcount, max.words = 100, colors = brewer.pal(8, "Dark2"))
```
```{r}
#9 How would you determine which character has the most spoken lines in the series?
charaText <- simpsons_script_lines$raw_character_text

spoken <- simpsons_script_lines %>%
  filter(speaking_line == TRUE) %>%
  group_by(raw_character_text) %>%
  summarise(total_lines = n()) %>%
  arrange(desc(total_lines))
head(spoken, 10)
```
Data Manipulation with Pandas
10 Using Pandas, how would you find the character who appeared in the most episodes?
11 How would you calculate the average word count per line of dialogue?
12 How would you merge episode data with script lines to analyze word count trends per season?

```{r}
#10 how would you find the character who appeared in the most episodes?
appear <- simpsons_script_lines %>%
  filter(!is.na(raw_character_text)) %>%
  group_by(raw_character_text) %>% 
  summarise(n = n_distinct(episode_id)) %>%
  arrange(desc(n)) 

```

```{r}
#11 How would you calculate the average word count per line of dialogue?

words <- simpsons_script_lines %>%
  filter(speaking_line == TRUE & word_count != 0) %>%
  summarise(avg = mean(word_count))

words
```

```{r}
#12 How would you merge episode data with script lines to analyze word count trends per season?
scriptEp2 <- simpsons_script_lines %>%
  left_join(simpsons_episodes, by = c("episode_id" = "id")) %>%
  filter(speaking_line == TRUE & word_count != 0) %>%
  group_by(season) %>%
  summarise(wordTrend = mean(word_count))


```
Machine Learning Applications
13 If you were to build a sentiment analysis model on Simpsons' script lines, how would you preprocess the text?
14 How would you build a model to predict an episodeâ€™s IMDb rating based on script data?
15 How could clustering be used to group characters based on their dialogue patterns?
```{r}
#13 If you were to build a sentiment analysis model on Simpsons' script lines, how would you preprocess the text?

```


